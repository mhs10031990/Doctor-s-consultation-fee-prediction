{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import RandomizedSearchCV,GridSearchCV\n",
    "from sklearn.preprocessing import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train = pd.read_excel(\"C:/Users/LENOVO/Desktop/Final_Train.xlsx\")\n",
    "data_test = pd.read_excel(\"C:/Users/LENOVO/Desktop/Final_Test.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to clean column Experience to retain only numbers.\n",
    "def exp_in_years(input_data):\n",
    "    return int(str([int(s) for s in str(input_data).split() if s.isdigit()]).replace(\"[\",\"\").replace(\"]\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to clean column Place to retain only City.\n",
    "def split_place(input_data):\n",
    "    return str(str(input_data).split(\",\")[1:2]).replace(\"[\",\"\").replace(\"]\",\"\").replace(\" \",\"\").replace(\"'\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to convert column Rating to scale number ranging from 0 to 10 (10 including)\n",
    "def convert_rating(input_data):\n",
    "    Rating = str(input_data).replace(\"%\",\"\")\n",
    "    if Rating.isdigit():\n",
    "        return np.round(int(Rating)/10,0)\n",
    "    else:\n",
    "        return '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Generalist = ['BHMS','BAMS','BUMS','BSAM','MBBS','BDS','BEMS','BIMS','BAc','BSc','LCEH','GAMS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Specialist = ['MD','MS','M','MD','MOrth','MDS','Masters','DNB','MA','MBA','MPH','MSc','MMed','MA','DMD','HMD','SC','MDEH','MOI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Super_Specialist = ['DM','MCh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PhD = ['PhD','Ph']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Diploma = ['DHMS','DIPLOMA','DLO','DCP','DAA','DDVL','DDV','DGO','DVD','DYA','DPM','DORL','IDCC','DNHE','Dip','NMD',\n",
    "           'PGDE','DDVCPS','PGDHA','PGD','DEMS','DDV','DD','DSM','DIH','DICOI','DAT','DRCOG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Membership = ['MFDS','MRCS','MRCP','MRCPS','MNAMS','MRSH','MRCPCH','MRCGP','MNAMS','MCIP','M','MRCEM','MAMS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Fellowship = ['Fellowship','FCGP','FAGE','FICP','FRCP','IBCLC','AFIH','FAMS','FRGUHS','FNB','FCSI','FSCAI','FRACS','FCAH',\n",
    "              'FIAMS','FRHS','FDSRCS','Fellow','FCPS','FFDRCSI','FICD','FICOI','FCCM','FCCP','FACE','FCIP','FCD','FACC',\n",
    "              'FSRH','FAAD','FCPS','FICS','FICA','FIAMS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Others = ['certification','certificate','GCEH','certified','CGO','CSD','CCDR','CCMTD','CCEDM','SCE','Course','Training'\n",
    "          ,'CCEBDM','Externship','ATLS','ACLS','BLS','CCST','PCAD','AFIH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to explode column Qualification\n",
    "def explode_qualification(input_data):\n",
    "    input_data['Generalist'] = input_data['Specialist'] = input_data['Super_Spec'] = input_data['PhD'] = input_data['Diploma'] = input_data['Membership'] = input_data['Fellowship']= input_data['Others']=pd.to_numeric(0)\n",
    "    \n",
    "    for i in range(0,len(input_data)):\n",
    "        temp = str(re.sub(r'[^\\w]',' ',input_data.loc[i,'Qualification'])).split()\n",
    "        input_data.loc[i,'Generalist'] = max([1 if X in Generalist else 0 for X in temp])\n",
    "        input_data.loc[i,'Specialist'] = max([1 if X in Specialist else 0 for X in temp ])\n",
    "        input_data.loc[i,'Super_Spec'] = max([1 if X in Super_Specialist else 0 for X in temp ])\n",
    "        input_data.loc[i,'PhD']        = max([1 if X in PhD else 0 for X in temp ]) \n",
    "        input_data.loc[i,'Diploma']    = max([1 if X in Diploma else 0 for X in temp ]) \n",
    "        input_data.loc[i,'Membership'] = max([1 if X in Membership else 0 for X in temp ]) \n",
    "        input_data.loc[i,'Fellowship'] = max([1 if X in Fellowship else 0 for X in temp ]) \n",
    "        input_data.loc[i,'Others']     = max([1 if X in Others else 0 for X in temp ])\n",
    "        \n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qualification            0\n",
       "Experience               0\n",
       "Rating                3302\n",
       "Place                   25\n",
       "Profile                  0\n",
       "Miscellaneous_Info    2620\n",
       "Fees                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to one hot encode City and Profile Columns.\n",
    "def one_hot(input_data):\n",
    "    return pd.get_dummies(input_data['City']), pd.get_dummies(input_data['Profile'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train['Exp'] = data_train['Experience'].apply(exp_in_years)\n",
    "data_test['Exp'] = data_test['Experience'].apply(exp_in_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "data_train['City'] = data_train['Place'].apply(split_place)\n",
    "data_train['City'][data_train['City'] == 'Sector5'] = 'Delhi'\n",
    "data_train['City'][data_train['City'] == ''] = 'Bangalore'\n",
    "\n",
    "data_test['City'] = data_test['Place'].apply(split_place)\n",
    "data_test['City'][data_test['City'] == 'Sector5'] = 'Delhi'\n",
    "data_test['City'][data_test['City'] == ''] = 'Bangalore'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "corrupt_data = data_train[data_train['City'] =='Unknown']\n",
    "data_train = data_train.drop(corrupt_data.index,axis=0)\n",
    "data_train.reset_index(inplace=True)\n",
    "--\n",
    "corrupt_data = data_test[data_test['City'] =='Unknown']\n",
    "data_test = data_test.drop(corrupt_data.index,axis=0)\n",
    "data_test.reset_index(inplace=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train['Rating'] = data_train['Rating'].apply(convert_rating)\n",
    "data_test['Rating'] = data_test['Rating'].apply(convert_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train = explode_qualification(data_train)\n",
    "data_test = explode_qualification(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Qualification</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Place</th>\n",
       "      <th>Profile</th>\n",
       "      <th>Miscellaneous_Info</th>\n",
       "      <th>Fees</th>\n",
       "      <th>Exp</th>\n",
       "      <th>City</th>\n",
       "      <th>Generalist</th>\n",
       "      <th>Specialist</th>\n",
       "      <th>Super_Spec</th>\n",
       "      <th>PhD</th>\n",
       "      <th>Diploma</th>\n",
       "      <th>Membership</th>\n",
       "      <th>Fellowship</th>\n",
       "      <th>Others</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BHMS, MD - Homeopathy</td>\n",
       "      <td>24 years experience</td>\n",
       "      <td>10</td>\n",
       "      <td>Kakkanad, Ernakulam</td>\n",
       "      <td>Homeopath</td>\n",
       "      <td>100% 16 Feedback Kakkanad, Ernakulam</td>\n",
       "      <td>100</td>\n",
       "      <td>24</td>\n",
       "      <td>Ernakulam</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BAMS, MD - Ayurveda Medicine</td>\n",
       "      <td>12 years experience</td>\n",
       "      <td>9</td>\n",
       "      <td>Whitefield, Bangalore</td>\n",
       "      <td>Ayurveda</td>\n",
       "      <td>98% 76 Feedback Whitefield, Bangalore</td>\n",
       "      <td>350</td>\n",
       "      <td>12</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MBBS, MS - Otorhinolaryngology</td>\n",
       "      <td>9 years experience</td>\n",
       "      <td>0</td>\n",
       "      <td>Mathikere - BEL, Bangalore</td>\n",
       "      <td>ENT Specialist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300</td>\n",
       "      <td>9</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BSc - Zoology, BAMS</td>\n",
       "      <td>12 years experience</td>\n",
       "      <td>0</td>\n",
       "      <td>Bannerghatta Road, Bangalore</td>\n",
       "      <td>Ayurveda</td>\n",
       "      <td>Bannerghatta Road, Bangalore ₹250 Available on...</td>\n",
       "      <td>250</td>\n",
       "      <td>12</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BAMS</td>\n",
       "      <td>20 years experience</td>\n",
       "      <td>10</td>\n",
       "      <td>Keelkattalai, Chennai</td>\n",
       "      <td>Ayurveda</td>\n",
       "      <td>100% 4 Feedback Keelkattalai, Chennai</td>\n",
       "      <td>250</td>\n",
       "      <td>20</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Qualification           Experience Rating  \\\n",
       "0           BHMS, MD - Homeopathy  24 years experience     10   \n",
       "1    BAMS, MD - Ayurveda Medicine  12 years experience      9   \n",
       "2  MBBS, MS - Otorhinolaryngology   9 years experience      0   \n",
       "3             BSc - Zoology, BAMS  12 years experience      0   \n",
       "4                            BAMS  20 years experience     10   \n",
       "\n",
       "                          Place         Profile  \\\n",
       "0           Kakkanad, Ernakulam       Homeopath   \n",
       "1         Whitefield, Bangalore        Ayurveda   \n",
       "2    Mathikere - BEL, Bangalore  ENT Specialist   \n",
       "3  Bannerghatta Road, Bangalore        Ayurveda   \n",
       "4         Keelkattalai, Chennai        Ayurveda   \n",
       "\n",
       "                                  Miscellaneous_Info  Fees  Exp       City  \\\n",
       "0               100% 16 Feedback Kakkanad, Ernakulam   100   24  Ernakulam   \n",
       "1              98% 76 Feedback Whitefield, Bangalore   350   12  Bangalore   \n",
       "2                                                NaN   300    9  Bangalore   \n",
       "3  Bannerghatta Road, Bangalore ₹250 Available on...   250   12  Bangalore   \n",
       "4              100% 4 Feedback Keelkattalai, Chennai   250   20    Chennai   \n",
       "\n",
       "   Generalist  Specialist  Super_Spec  PhD  Diploma  Membership  Fellowship  \\\n",
       "0           1           1           0    0        0           0           0   \n",
       "1           1           1           0    0        0           0           0   \n",
       "2           1           1           0    0        0           0           0   \n",
       "3           1           0           0    0        0           0           0   \n",
       "4           1           0           0    0        0           0           0   \n",
       "\n",
       "   Others  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train = data_train.join(one_hot(data_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_test = data_test.join(one_hot(data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train = data_train.drop(['Qualification','Experience','Rating','Place','Profile','Miscellaneous_Info','City'], axis=1)\n",
    "data_test = data_test.drop(['Qualification','Experience','Rating','Place','Profile','Miscellaneous_Info','City'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_Feature = data_train[[x for x in data_train.columns if (x != 'Fees' and x != 'index')]]\n",
    "train_Target = data_train['Fees']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_Feature, train_Target, test_size=0.30, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([               u'Exp',         u'Generalist',         u'Specialist',\n",
       "               u'Super_Spec',                u'PhD',            u'Diploma',\n",
       "               u'Membership',         u'Fellowship',             u'Others',\n",
       "                u'Bangalore',            u'Chennai',         u'Coimbatore',\n",
       "                    u'Delhi',          u'Ernakulam',          u'Hyderabad',\n",
       "                   u'Mumbai', u'Thiruvananthapuram',           u'Ayurveda',\n",
       "                  u'Dentist',     u'Dermatologists',     u'ENT Specialist',\n",
       "         u'General Medicine',          u'Homeopath'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.columns\n",
    "#data_test.drop(['index'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5961"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_Feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test-MLE/MSLE: ', 169.65475305756186, 0.6635604144071413)\n",
      "('Train-MLE/MSLE: ', 174.65031198033626, 0.6506883241281446)\n"
     ]
    }
   ],
   "source": [
    "#Model_1\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "y_pred_test = regr.predict(X_test)\n",
    "y_pred_train = regr.predict(X_train)\n",
    "test_mse = sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "test_msle = sqrt(mean_squared_log_error(y_test, y_pred_test))\n",
    "\n",
    "train_mse = sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "train_msle = sqrt(mean_squared_log_error(y_train, y_pred_train))\n",
    "\n",
    "print (\"Test-MLE/MSLE: \", test_mse, test_msle)\n",
    "print (\"Train-MLE/MSLE: \", train_mse, train_msle)\n",
    "\n",
    "predictions = pd.DataFrame(np.round(regr.predict(data_test),0),columns=['Fees'])\n",
    "predictions.to_excel(\"C:/Users/LENOVO/Desktop/Basic_LR.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test-MLE/MSLE: ', 177.70953323625955, 0.6648195119343969)\n",
      "('Train-MLE/MSLE: ', 132.47335244433887, 0.5115458732686278)\n"
     ]
    }
   ],
   "source": [
    "#Model_2\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42, max_depth=15)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_test = rf.predict(X_test)\n",
    "y_pred_train = rf.predict(X_train)\n",
    "test_mse = sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "test_msle = sqrt(mean_squared_log_error(y_test, y_pred_test))\n",
    "\n",
    "train_mse = sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "train_msle = sqrt(mean_squared_log_error(y_train, y_pred_train))\n",
    "\n",
    "print (\"Test-MLE/MSLE: \", test_mse, test_msle)\n",
    "print (\"Train-MLE/MSLE: \", train_mse, train_msle)\n",
    "\n",
    "predictions = pd.DataFrame(np.round(rf.predict(data_test),0),columns=['Fees'])\n",
    "predictions.to_excel(\"C:/Users/LENOVO/Desktop/RandomForest.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Features: 15\n",
      "Selected Features: [False False False  True False False False False False  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True]\n",
      "Feature Ranking: [9 3 2 1 7 8 4 5 6 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[('Exp', 9), ('Generalist', 3), ('Specialist', 2), ('Super_Spec', 1), ('PhD', 7), ('Diploma', 8), ('Membership', 4), ('Fellowship', 5), ('Others', 6), ('Bangalore', 1), ('Chennai', 1), ('Coimbatore', 1), ('Delhi', 1), ('Ernakulam', 1), ('Hyderabad', 1), ('Mumbai', 1), ('Thiruvananthapuram', 1), (u'Ayurveda', 1), (u'Dentist', 1), (u'Dermatologists', 1), (u'ENT Specialist', 1), (u'General Medicine', 1), (u'Homeopath', 1)]\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "rfe = RFE(regr,15)\n",
    "fit = rfe.fit(X_train, y_train)\n",
    "\n",
    "print(\"Num Features: %d\") % fit.n_features_\n",
    "print(\"Selected Features: %s\") % fit.support_\n",
    "print(\"Feature Ranking: %s\") % fit.ranking_\n",
    "print (zip(X_train.columns, fit.ranking_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed: 17.6min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 33.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise',\n",
       "          estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=100, n_jobs=-1,\n",
       "          param_distributions={'bootstrap': [True, False], 'min_samples_leaf': [1, 2, 4], 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'min_samples_split': [2, 5, 10], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=2)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor()\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, \n",
    "                               n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=90,\n",
       "           max_features='sqrt', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=4, min_samples_split=10,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=400, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test-MLE/MSLE: ', 167.426300913272, 0.6489040886651221)\n",
      "('Train-MLE/MSLE: ', 163.3495524066283, 0.6140572015828599)\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = rf_random.predict(X_test)\n",
    "y_pred_train = rf_random.predict(X_train)\n",
    "test_mse = sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "test_msle = sqrt(mean_squared_log_error(y_test, y_pred_test))\n",
    "\n",
    "train_mse = sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "train_msle = sqrt(mean_squared_log_error(y_train, y_pred_train))\n",
    "\n",
    "print (\"Test-MLE/MSLE: \", test_mse, test_msle)\n",
    "print (\"Train-MLE/MSLE: \", train_mse, train_msle)\n",
    "\n",
    "predictions = pd.DataFrame(np.round(rf_random.predict(data_test),0),columns=['Fees'])\n",
    "predictions.to_excel(\"C:/Users/LENOVO/Desktop/RandomSearch.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Model 3 Randomforest with GridSearch Cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [10,20,30,40,50],\n",
    "    'max_features': [2,3],\n",
    "    'min_samples_leaf': [3,4,5],\n",
    "    'min_samples_split': [8,10,12],\n",
    "    'n_estimators': [100,200,400,600,800]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 450 candidates, totalling 1350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   53.3s\n",
      "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 361 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=-1)]: Done 644 tasks      | elapsed: 16.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1009 tasks      | elapsed: 26.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1350 out of 1350 | elapsed: 35.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'bootstrap': [True], 'min_samples_leaf': [3, 4, 5], 'n_estimators': [100, 200, 400, 600, 800], 'min_samples_split': [8, 10, 12], 'max_features': [2, 3], 'max_depth': [10, 20, 30, 40, 50]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=2)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=50,\n",
       "           max_features=3, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=3,\n",
       "           min_samples_split=12, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=600, n_jobs=1, oob_score=False, random_state=None,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test-MLE/MSLE: ', 167.34642592345756, 0.6486736535649416)\n",
      "('Train-MLE/MSLE: ', 162.43438164524466, 0.6115685430267621)\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = grid_search.predict(X_test)\n",
    "y_pred_train = grid_search.predict(X_train)\n",
    "test_mse = sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "test_msle = sqrt(mean_squared_log_error(y_test, y_pred_test))\n",
    "\n",
    "train_mse = sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "train_msle = sqrt(mean_squared_log_error(y_train, y_pred_train))\n",
    "\n",
    "print (\"Test-MLE/MSLE: \", test_mse, test_msle)\n",
    "print (\"Train-MLE/MSLE: \", train_mse, train_msle)\n",
    "\n",
    "predictions = pd.DataFrame(np.round(grid_search.predict(data_test),0),columns=['Fees'])\n",
    "predictions.to_excel(\"C:/Users/LENOVO/Desktop/GridSearch.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Model 4 GridSearch with more parameters.\n",
    "param_grid = {\n",
    "    'bootstrap': [True, False],\n",
    "    'max_depth': [40,50,60,70,80],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'min_samples_leaf': [3,4,5],\n",
    "    'min_samples_split': [6,7,8],\n",
    "    'n_estimators': [500,600,700,800,900,1000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1620 candidates, totalling 4860 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed: 12.7min\n",
      "[Parallel(n_jobs=-1)]: Done 361 tasks      | elapsed: 22.8min\n",
      "[Parallel(n_jobs=-1)]: Done 644 tasks      | elapsed: 40.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1009 tasks      | elapsed: 57.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1454 tasks      | elapsed: 81.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1981 tasks      | elapsed: 112.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2588 tasks      | elapsed: 150.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3277 tasks      | elapsed: 201.9min\n",
      "[Parallel(n_jobs=-1)]: Done 4046 tasks      | elapsed: 257.5min\n",
      "[Parallel(n_jobs=-1)]: Done 4860 out of 4860 | elapsed: 308.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'bootstrap': [True, False], 'min_samples_leaf': [3, 4, 5], 'n_estimators': [500, 600, 700, 800, 900, 1000], 'min_samples_split': [6, 7, 8], 'max_features': ['auto', 'sqrt', 'log2'], 'max_depth': [40, 50, 60, 70, 80]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=2)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=80,\n",
       "           max_features='sqrt', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=5, min_samples_split=8,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test-MLE/MSLE: ', 167.12934229284443, 0.6480875111068343)\n",
      "('Train-MLE/MSLE: ', 164.7960783318647, 0.6186863000480827)\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = grid_search.predict(X_test)\n",
    "y_pred_train = grid_search.predict(X_train)\n",
    "test_mse = sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "test_msle = sqrt(mean_squared_log_error(y_test, y_pred_test))\n",
    "\n",
    "train_mse = sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "train_msle = sqrt(mean_squared_log_error(y_train, y_pred_train))\n",
    "\n",
    "print (\"Test-MLE/MSLE: \", test_mse, test_msle)\n",
    "print (\"Train-MLE/MSLE: \", train_mse, train_msle)\n",
    "\n",
    "predictions = pd.DataFrame(np.round(grid_search.predict(data_test),0),columns=['Fees'])\n",
    "predictions.to_excel(\"C:/Users/LENOVO/Desktop/GridSearch_v1.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
